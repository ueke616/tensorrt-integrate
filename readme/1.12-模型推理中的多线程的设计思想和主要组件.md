# 知识点
- main.cpp里有三个函数分别对应 学习 condition variable, promise 和 future, multithread的设计模式
  - condition_variable_test();
    - 抖音短视频讲解： 图解条件变量【建议1.5倍速】 https://www.douyin.com/discover?modal_id=7077594461357821221
    - 抖音短视频讲解： 条件变量代码【建议1.5倍速】 https://www.douyin.com/discover?modal_id=7077595098422283533
    
  - future_test();
    - 抖音短视频讲解： promise和future理论部分【建议1.5倍速】https://www.douyin.com/discover?modal_id=7077477959841418509
    - 抖音短视频讲解： promise和future代码部分【建议1.5倍速】https://www.douyin.com/discover?modal_id=7077488260234169630
  
  - infer_test();
    - 【建议】抖音短视频讲解已经嵌在了代码里，阅读代码时可点击打开
    -  也可以快速浏览合集 https://www.douyin.com/video/7077599352822222116

- 运行
  - `make run`
- condition_variable_test();
- future_test();
- infer_test();

# 运行
- `make run`

# 相关视频
- https://v.douyin.com/NfJ9kYy/

RAII+接口模式的生产者封装, 以及多batch的体现(TensorRT高性能的保障)

/////////////////////////////////////////////////////

RAII（Resource Acquisition Is Initialization）是一种在C++中管理资源（如动态分配的内存、文件句柄、网络连接等）的编程技术。RAII的核心思想是利用局部对象的生命周期自动管理资源，通过对象的构造函数获取资源，并在析构函数中释放资源，确保资源的正确释放，即使在发生异常时也能保证资源不会泄露。

### RAII的优势
- **自动资源管理**：利用对象的构造和析构，自动完成资源的获取和释放。
- **异常安全**：即使在代码执行过程中发生异常，局部对象的析构函数仍然会被调用，从而释放资源。
- **简化资源管理代码**：将资源管理逻辑封装在对象中，简化了资源的管理，使代码更加清晰。

### 接口模式
接口模式（Interface Pattern），也称策略模式，是一种设计模式，它定义了一系列算法，并将每一种算法封装起来，使它们可以互相替换。这个模式让算法的变化独立于使用算法的客户。在C++中，接口一般通过纯虚函数（抽象类）来实现，允许实现类以不同的方式执行操作。

### RAII + 接口模式的结合
将RAII与接口模式结合，可以创建一套强大的设计，用于资源管理和策略的灵活切换。例如，可以设计一个资源管理类，这个类遵循RAII原则管理资源，同时通过接口暴露给客户端，允许使用不同的策略或实现来管理资源。

```cpp
#include <iostream>

// 资源接口
class IResource {
public:
    virtual ~IResource() {} // 确保派生类的析构函数被调用
    virtual void useResource() = 0; // 纯虚函数，子类需要实现
};

// 具体资源实现
class FileResource : public IResource {
public:
    FileResource() {
        // 资源获取
        std::cout << "FileResource acquired\n";
    }

    ~FileResource() {
        // 资源释放
        std::cout << "FileResource released\n";
    }

    void useResource() override {
        std::cout << "Using FileResource\n";
    }
};

// 资源管理类，使用RAII管理资源对象
class ResourceManager {
    IResource* resource;

public:
    ResourceManager(IResource* r) : resource(r) {}

    ~ResourceManager() {
        delete resource;
    }

    void use() {
        resource->useResource();
    }
};

int main() {
    // 使用具体资源
    ResourceManager manager(new FileResource());
    manager.use();
    // 当manager出作用域时，自动释放FileResource
    return 0;
}
```

这个例子展示了如何通过接口和RAII结合管理资源。`FileResource`类实现了`IResource`接口，`ResourceManager`类在构造函数中获取资源，在析构函数中释放资源。这种设计既利用了RAII确保资源正确管理，也通过接口提供了扩展性，允许未来以最小的修改支持更多类型的资源。

///////////////////////////////////

## 多 batch(Batching) 是TensorRT实现高性能的基础 (并行)

理解为什么多Batch（Batching）是TensorRT实现高性能的基础，首先需要了解深度学习模型推理（Inference）中Batch的概念，以及它是如何影响性能的。

### Batch的概念
在深度学习中，一个"Batch"指的是一次性处理的数据集合，例如一组图像。Batch大小（即Batch中包含的数据项数量）直接影响到模型推理的性能和效率。

### 多Batch带来的性能优势
1. **硬件资源利用率提高**：现代硬件（如GPU）设计有大量并行处理单元。通过同时处理多个数据项（即增加Batch大小），可以更充分地利用这些并行处理单元，从而提高计算效率和吞吐量。
2. **内存访问优化**：深度学习模型推理涉及大量的矩阵运算。处理更大的Batch可以优化内存访问模式，比如减少访问延迟、增加缓存命中率，这在GPU上尤其重要。
3. **减少启动开销**：每次执行推理任务时，都会有一定的启动开销（如加载模型到GPU、初始化资源等）。通过一次处理更多数据减少推理次数，可以相对减少这部分开销在总处理时间中所占的比例。

### TensorRT中的多Batch优化
TensorRT是一个用于高性能深度学习推理的优化库，它提供了多种针对特定硬件的优化技术。在TensorRT中，通过支持多Batch处理，可以充分利用上述优势，达到以下目的：
- **层融合（Layer Fusion）**：将多个操作融合为一个操作，减少内存访问次数和计算量。
- **内核自动调整（Kernel Auto-Tuning）**：针对不同的Batch大小，自动选择最优的算法和计算路径。
- **动态张量内存（Dynamic Tensor Memory）**：动态管理内存，以支持不同大小的Batch，进一步提高内存利用效率。
- **精度校准（Precision Calibration）**：根据实际运行时数据和Batch大小，自动选择最佳的精度模式，以在保证精度的前提下提高性能。

总之，多Batch处理是提高深度学习推理性能的关键技术之一。TensorRT通过一系列针对多Batch优化的技术，能够显著提高处理速度和效率，尤其是在资源丰富的GPU上。

流是任务并行，Batch是数据层面的并行

////////////////////////////////

RAII + 接口模式	来实现
接口类, 他是一个纯虚类
原则是: ![只暴露调用者需要的函数, 其他一概不暴露]
比如说 load_model, 咱们通过RAII做了定义, 因此load_model属于不需要的范畴
内部如果有启动线程等等, start、stop, 也不需要暴露, 而是初始化的时候就自动启动, 都是RAII的定义

