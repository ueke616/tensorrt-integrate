# 知识点
1. 源自这个项目：https://github.com/iwatake2222/self-driving-ish_computer_vision_system

# 引用
1. 深度估计：https://github.com/tjqansthd/LapDepth-release
2. 模型动物园：https://github.com/PINTO0309/PINTO_model_zoo/
3. Intel模型动物园：https://github.com/openvinotoolkit/open_model_zoo

https://github.com/iwatake2222/self-driving-ish_computer_vision_system


/////////////////////////////////////////////

道路分割分析

找到道路分割的onnx, 分析其 onnx 的大致使用逻辑, 然后写出最简洁版本的 predict.py

1. 打开道路分割的onnx, 查看其输入和输出
2. 查看代码, 找到 onnx 的预处理, 分析得到预处理的逻辑
3. 针对获得的信息, 编写 predict.py, 尝试写出来

///////////////////////////////////////////

## road-segmentation-adas-0001.onnx 的模型分析
1. 输入是 1x3x512x896
2. 输出是 1x512x896x4, 并且是概率值, 0-1, 仅仅是不确定 4 通道代表什么。
    - 可行驶区域
    - 车道线
    - 不可行驶区域
    - 马路牙子
3. normalize -> mean = 0, norm = 1
4. 对输入图像直接 resize 到 height = 512, width = 896
5. 确定输入的就是 RGB 图像
6. normalize = (src_image - normalize.mean) * normalize.norm

## Idrn_kitti_resnet101_pretrained.onnx 的模型分析
1. 输入是 1x3x256x512, input.1
2. 输出是 1x3x256x512, 是 2499 节点
3. normalize.mean = 0.485f, norm = 0.229f
    - new_mean = mean * 255
    - new_norm = 1 / (norm * 255)
    - y = (x - new_mean) * new_norm
    - y = (x - mean * 255) * 1 / (norm * 255)
    - y = (x - mean * 255) * 1 / 255 * 1 / norm
    - y = (x / 255 - mean) / norm
4. resize部分, 不要搞那么复杂, 直接 resize
5. 颜色方面, 需要 cvtColor -> to RGB

## 车道线检测分析

目前最新的, 大家更倾向于位置概率点乘其位置作为输出值, 属于加权和
即, 将回归的坐标以 n 个位置概率进行表示, 例如对于 cx 的回归, 表示为 5 个 概率, 可认为对图像划分为 5 块, 然后 cx 更有可能落到哪一块上进行表述。例如落在图片中心上时, 其中心概率最高。类似于attention

比如 NanoDet:
https://zhuanlan.zhihu.com/p/649761951
https://blog.csdn.net/qq_41204464/article/details/110410940

车道线的预测逻辑：
一般以车辆行驶图片的中间线开始, 往下预测半张(上半张是天空)。然后一般是预测4道线(当前行驶车道2条, 左右车道线2条)。然后用点表示车道线, 点的 y 轴是固定的, 比如说把下半图片横向分割成18分, 然后纵向再分割成若干份(如200份, 会比横向更细), 那么车道线会落到网格上。 用回归来预测点的概率值, 

## 对车道线检测模型的分析
1. 输入是: 1x3x288x800
2. 输出是: 1x201x18x4
3. 对于车道线检测任务而言有一些定义或者说是先验
    - 只需要识别 4 根线
    - 对于车道线基本是在地面上的, 因此, y 方向可以从图像中心开始, 也就是 achor 起始坐标是图像中心到图像底部
    - 对于对于车道线的检测, 因为线是连续的, 因此这里可以转变为离散的点检测, 对于一根线可以设计为 18 个点来描述
    - 因此回归一个点, 其 y 坐标已知, x 坐标需要回归出来
    - 对于 x 的回归, 采用了位置概率来表示, 划分为 200 个网格表示其坐标
    - 对于车道线的点是否存在这个问题, 采用第 201 个概率表示。 若这个点不存在, 则 201 个位置的值是最大的
### 下面操作在 1.20-self-driving/self-driving-ish_computer_vision_system/image_processor/lane_engine.cpp 也可找到
我们的实现 lane-detection.py
4. 图像的预处理直接是 image / 255
5. 图像需要从 BGR 到 RGB
6. 图像 resize 到 (288, 800)
7. 后处理部分:
    - 对 0-200 (纵向网格)维度进行 softmax, 此时得到的是位置概率
    - 对位置概率和位置索引点乘相加, 得到 location, 此时 location 是 18x4(点、线)
    - 对原始输出的最大值进行判断, 决定该点是否存在
    - 最后通过过滤得到 4 根线的坐标

导出最后模型在 change-lane-onnx.py中, 在原模型上又加了后处理的代码

//////////////////////////////////

## trtpy 更新当前项目案例
trtpy get-series tensorrt-integrate --download
trtpy series-detail tensorrt-integrate --download

## 报错 OpenCV: FFMPEG: tag 0x3247504d/'MPG2' is not supported with codec id 2 and format 'mp4 / MP4 (MPEG-4 Part 14)'
https://blog.csdn.net/u010420283/article/details/89706794

## 报错 Serialization assertion plan->header.magicTag == rt::kPLAN_MAGIC_TAG failed.
您正在使用不同的 TRT 版本来构建引擎并对其进行反序列化。或者您正在使用不同的设备来构建引擎并对其进行反序列化。
